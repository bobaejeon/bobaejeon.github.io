
@article{jeon_personalized_2025,
	title = {Personalized {Visual} {Dubbing} through {Virtual} {Dubber} and {Full} {Head} {Reenactment}},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://diglib.eg.org/handle/10.2312/egs20251034},
	doi = {10.2312/EGS.20251034},
	abstract = {Visual dubbing aims to modify facial expressions to ''lip-sync'' a new audio track. While person-generic talking head generation methods achieve expressive lip synchronization across arbitrary identities, they usually lack person-specific details and fail to generate high-quality results. Conversely, person-specific methods require extensive training. Our method combines the strengths of both methods by incorporating a virtual dubber, a person-generic talking head, as an intermediate representation. We then employ an autoencoder-based person-specific identity swapping network to transfer the actor identity, enabling fullhead reenactment that includes hair, face, ears, and neck. This eliminates artifacts while ensuring temporal consistency. Our quantitative and qualitative evaluation demonstrate that our method achieves a superior balance between lip-sync accuracy and realistic facial reenactment.},
	urldate = {2025-05-28},
	journal = {Eurographics 2025 - Short Papers},
	author = {Jeon, Bobae and Paquette, Eric and Mudur, Sudhir and Popa, Tiberiu},
	year = {2025},
	note = {Artwork Size: 4 pages
Edition: 1034
ISBN: 9783038682684
Publisher: The Eurographics Association},
	keywords = {Animation, CCS Concepts: Computing methodologies → Image manipulation; Animation, Computing methodologies → Image manipulation},
	annote = {Other
Short Paper 2Other
Bobae Jeon, Eric Paquette, Sudhir Mudur, and Tiberiu Popa},
}
